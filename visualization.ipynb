{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e840c3d9-ed97-4aaf-bc84-78bdc0a4be26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "pio.renderers.default = \"iframe_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47b9c5f-357d-4f91-a617-38f2a464878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a701a3f1-6c3d-4c16-97cb-41517ad7e9b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns: ['Token', 'Lemma']\n",
      "\n",
      "preview:\n"
     ]
    }
   ],
   "source": [
    "p = r\"data\\csv\\SNP2719372X-19180101-0-0-0-0.csv\"   # <-- change this to one file\n",
    "df = pd.read_csv(p, nrows=3, encoding=\"utf-8\")   # try utf-8 first\n",
    "print(\"columns:\", list(df.columns))\n",
    "print(\"\\npreview:\")\n",
    "#display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a30bed-88b6-4178-b70d-6f6ee4e74d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1323 csv files\n",
      "\n",
      "SNP27112366-19180101-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180102-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180103-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180104-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180105-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180106-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180107-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180108-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180109-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180110-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180111-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180112-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180113-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180114-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180115-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180116-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180117-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180118-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180119-0-0-0-0.csv -> ('Token', 'Lemma')\n",
      "SNP27112366-19180120-0-0-0-0.csv -> ('Token', 'Lemma')\n"
     ]
    }
   ],
   "source": [
    "folder = Path(r\"data\\csv\")\n",
    "csvs = sorted(folder.glob(\"*.csv\"))\n",
    "print(f\"found {len(csvs)} csv files\\n\")\n",
    "\n",
    "headers = {}\n",
    "for f in csvs:\n",
    "    try:\n",
    "        h = list(pd.read_csv(f, nrows=0, encoding=\"utf-8\").columns)\n",
    "    except Exception:\n",
    "        try:\n",
    "            h = list(pd.read_csv(f, nrows=0, encoding=\"latin1\").columns)\n",
    "        except Exception as e:\n",
    "            h = [f\"ERROR: {e}\"]\n",
    "    headers[f.name] = tuple(h)\n",
    "\n",
    "# show first 20 files and their headers\n",
    "for i, (name, cols) in enumerate(headers.items()):\n",
    "    if i < 20:\n",
    "        print(f\"{name} -> {cols}\")\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0e5f1c9-9bf3-4937-8607-4843621e0f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct schemas: 1\n",
      "1323 files -> ('Token', 'Lemma')\n"
     ]
    }
   ],
   "source": [
    "schema_counts = Counter(headers.values())\n",
    "print(\"Number of distinct schemas:\", len(schema_counts))\n",
    "for cols, cnt in schema_counts.most_common():\n",
    "    print(f\"{cnt} files -> {cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f607a83-cf27-48ce-a8ab-b2ebd2a835d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1323/1323 [00:17<00:00, 73.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape: (33185569, 3)\n"
     ]
    }
   ],
   "source": [
    "folder = Path(r\"data\\csv\")   # <-- change this\n",
    "files = sorted(folder.glob(\"*.csv\"))\n",
    "\n",
    "dfs = []\n",
    "for f in tqdm(files):\n",
    "    df = pd.read_csv(f, encoding=\"utf-8\")\n",
    "    df[\"source_file\"] = f.stem  # store filename (without .csv)\n",
    "    dfs.append(df)\n",
    "\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Combined shape:\", df_all.shape)\n",
    "#df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "006578e3-e4fe-4b22-8cc0-c9e710483bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SNP27112366-19180101-0-0-0-0', 'SNP27112366-19180102-0-0-0-0',\n",
       "       'SNP27112366-19180103-0-0-0-0', 'SNP27112366-19180104-0-0-0-0',\n",
       "       'SNP27112366-19180105-0-0-0-0', 'SNP27112366-19180106-0-0-0-0',\n",
       "       'SNP27112366-19180107-0-0-0-0', 'SNP27112366-19180108-0-0-0-0',\n",
       "       'SNP27112366-19180109-0-0-0-0', 'SNP27112366-19180110-0-0-0-0',\n",
       "       'SNP27112366-19180111-0-0-0-0', 'SNP27112366-19180112-0-0-0-0',\n",
       "       'SNP27112366-19180113-0-0-0-0', 'SNP27112366-19180114-0-0-0-0',\n",
       "       'SNP27112366-19180115-0-0-0-0', 'SNP27112366-19180116-0-0-0-0',\n",
       "       'SNP27112366-19180117-0-0-0-0', 'SNP27112366-19180118-0-0-0-0',\n",
       "       'SNP27112366-19180119-0-0-0-0', 'SNP27112366-19180120-0-0-0-0'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"source_file\"].unique()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "050eb835-a888-4516-8000-6d6fa68b362f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SNP27112366-19180101-0-0-0-0</td>\n",
       "      <td>1918-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SNP27112366-19180101-0-0-0-0</td>\n",
       "      <td>1918-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SNP27112366-19180101-0-0-0-0</td>\n",
       "      <td>1918-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SNP27112366-19180101-0-0-0-0</td>\n",
       "      <td>1918-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SNP27112366-19180101-0-0-0-0</td>\n",
       "      <td>1918-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source_file       date\n",
       "0  SNP27112366-19180101-0-0-0-0 1918-01-01\n",
       "1  SNP27112366-19180101-0-0-0-0 1918-01-01\n",
       "2  SNP27112366-19180101-0-0-0-0 1918-01-01\n",
       "3  SNP27112366-19180101-0-0-0-0 1918-01-01\n",
       "4  SNP27112366-19180101-0-0-0-0 1918-01-01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the 8-digit date part using a regex\n",
    "df_all[\"date\"] = df_all[\"source_file\"].str.extract(r\"-(\\d{8})-\")\n",
    "\n",
    "# convert to datetime\n",
    "df_all[\"date\"] = pd.to_datetime(df_all[\"date\"], format=\"%Y%m%d\")\n",
    "\n",
    "# quick check\n",
    "df_all[[\"source_file\", \"date\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "958c6f40-6231-443f-9a34-999e104feae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('1918-01-01 00:00:00'), Timestamp('1919-12-31 00:00:00'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all[\"date\"].min(), df_all[\"date\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "885418af-a106-42b4-8dba-587e80d55718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase lemmas\n",
    "df_all[\"Lemma_lower\"] = df_all[\"Lemma\"].str.lower()\n",
    "\n",
    "# keep only alphabetic words longer than 2 letters\n",
    "df_all_filtered = df_all[df_all[\"Lemma_lower\"].str.isalpha() & (df_all[\"Lemma_lower\"].str.len() > 2)]\n",
    "\n",
    "german_stopwords = set(stopwords.words(\"german\"))\n",
    "custom_stopwords = {\n",
    "    \"auch\", \"noch\", \"wird\", \"sein\", \"einer\", \"einem\", \"eines\", \n",
    "    \"sich\", \"wurde\", \"wären\", \"kann\", \"können\", \"dass\", \"sind\",\n",
    "    \"wurde\", \"waren\", \"haben\", \"hatte\", \"worden\", \"diese\",\n",
    "    \"dieser\", \"dieses\", \"diesen\", \"jahr\", \"zeit\", \"zeitung\"\n",
    "}\n",
    "extended_stopwords = german_stopwords.union(custom_stopwords)\n",
    "\n",
    "df_all_filtered = df_all_filtered[~df_all_filtered[\"Lemma_lower\"].isin(extended_stopwords)]\n",
    "\n",
    "# calculate frequencies per lemma per date\n",
    "lemma_date_counts = (\n",
    "    df_all_filtered.groupby([\"date\", \"Lemma_lower\"])\n",
    "    .size()\n",
    "    .reset_index(name=\"count\")\n",
    ")\n",
    "\n",
    "# remove rare lemmas (<5 occurrences)\n",
    "lemma_date_counts = lemma_date_counts[lemma_date_counts[\"count\"] >= 5]\n",
    "\n",
    "# quick check\n",
    "#lemma_date_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20efe909-6e16-496f-8c3b-ea1ffc7f8e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = ['grippe','tote','influenza','pandemie','epidemie','krankheit','tag','hoch','kampf','kreis','mensch','täglich','tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2d4eab5-f052-4541-ba91-26e8326bd797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique dates containing flu-related words: 700\n"
     ]
    }
   ],
   "source": [
    "dates_with_flu = lemma_date_counts[\n",
    "    lemma_date_counts['Lemma_lower'].isin(seed_words)\n",
    "]['date'].unique()\n",
    "\n",
    "print(f\"Number of unique dates containing flu-related words: {len(dates_with_flu)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db384dd4-15f8-4310-a29c-726cbbc2480c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows in co-occurrence set: 348909\n"
     ]
    }
   ],
   "source": [
    "# take all rows where the date is in the flu-related dates\n",
    "df_co = lemma_date_counts[lemma_date_counts['date'].isin(dates_with_flu)].copy()\n",
    "\n",
    "# check size and sample\n",
    "print(f\"Total rows in co-occurrence set: {len(df_co)}\")\n",
    "#print(df_co.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9575b5e3-5b71-4518-bb90-64b89d440d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a set of seed words for fast lookup\n",
    "seed_set = set(seed_words)\n",
    "\n",
    "# 2. For each date, get all lemmas appearing\n",
    "lemmas_by_date = df_co.groupby('date')['Lemma_lower'].apply(set)\n",
    "\n",
    "# 3. Count co-occurrences: if a seed word is on a date, increment count for all lemmas on that date\n",
    "co_counts = Counter()\n",
    "\n",
    "for date, lemmas in lemmas_by_date.items():\n",
    "    if seed_set & lemmas:  # any seed word present\n",
    "        for lemma in lemmas:\n",
    "            if lemma not in seed_set:  # exclude seed words themselves\n",
    "                co_counts[lemma] += 1\n",
    "\n",
    "# 4. Convert to DataFrame and sort\n",
    "df_cooccurrence = (\n",
    "    pd.DataFrame(co_counts.items(), columns=['Lemma_lower', 'co_occurrence_count'])\n",
    "    .sort_values(by='co_occurrence_count', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "#print(df_cooccurrence.head(20))  # top 20 co-occurring lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a23d19f-bbad-4bc5-a4b6-23e2d9bc9e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 50\n",
    "flu_vocab = df_cooccurrence['Lemma_lower'].head(top_n).tolist() + seed_words  # include seed words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57ae29d6-5ca4-4acc-baa7-f66d8977c5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_words = ['grippe','tote','influenza','pandemie','epidemie','krankheit','hoch','kampf','kreis','mensch','täglich','tot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac37f15-a9a7-463e-992d-9e0c12a5547d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the seed-only DataFrame: (2300, 3)\n"
     ]
    }
   ],
   "source": [
    "# Filter 'lemma_date_counts' to keep only rows where the lemma is in the seed words\n",
    "df_flu_seed_only = lemma_date_counts[\n",
    "    lemma_date_counts['Lemma_lower'].isin(seed_words)\n",
    "].copy()\n",
    "\n",
    "# Sort by date for readability\n",
    "df_flu_seed_only = df_flu_seed_only.sort_values(by=['date', 'count'], ascending=[True, False])\n",
    "\n",
    "# Print the head and shape of this new DataFrame\n",
    "print(f\"Shape of the seed-only DataFrame: {df_flu_seed_only.shape}\")\n",
    "#print(\"\\nPreview of the seed-only DataFrame (top 10 rows):\")\n",
    "#print(df_flu_seed_only.head(10).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "235a4634-1f3b-4b42-92ce-a3e31ee6f24c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"970px\"\n",
       "    height=\"570\"\n",
       "    src=\"iframe_figures/figure_18.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "# --- Aggregate totals for plotting ---\n",
    "daily_total = (\n",
    "    df_flu_seed_only.groupby('date')['count']\n",
    "    .sum()\n",
    "    .reset_index(name='total_abs_freq')\n",
    ")\n",
    "\n",
    "df_flu_seed_only['week'] = df_flu_seed_only['date'].dt.to_period('W').dt.start_time\n",
    "weekly_total = (\n",
    "    df_flu_seed_only.groupby('week')['count']\n",
    "    .sum()\n",
    "    .reset_index(name='total_abs_freq')\n",
    ")\n",
    "\n",
    "df_flu_seed_only['month'] = df_flu_seed_only['date'].dt.to_period('M').dt.start_time\n",
    "monthly_total = (\n",
    "    df_flu_seed_only.groupby('month')['count']\n",
    "    .sum()\n",
    "    .reset_index(name='total_abs_freq')\n",
    ")\n",
    "\n",
    "# --- Create Plotly figure ---\n",
    "fig = go.Figure()\n",
    "\n",
    "# Daily\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=daily_total['date'], y=daily_total['total_abs_freq'],\n",
    "    mode='lines', name='Daily', visible=True\n",
    "))\n",
    "\n",
    "# Weekly\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=weekly_total['week'], y=weekly_total['total_abs_freq'],\n",
    "    mode='lines', name='Weekly', visible=False\n",
    "))\n",
    "\n",
    "# Monthly\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=monthly_total['month'], y=monthly_total['total_abs_freq'],\n",
    "    mode='lines', name='Monthly', visible=False\n",
    "))\n",
    "\n",
    "# --- Toggle buttons ---\n",
    "buttons = [\n",
    "    dict(label='Daily',\n",
    "         method='update',\n",
    "         args=[{'visible': [True, False, False]},\n",
    "               {'title': 'Total Daily Mentions of Flu-related Words'}]),\n",
    "    dict(label='Weekly',\n",
    "         method='update',\n",
    "         args=[{'visible': [False, True, False]},\n",
    "               {'title': 'Total Weekly Mentions of Flu-related Words'}]),\n",
    "    dict(label='Monthly',\n",
    "         method='update',\n",
    "         args=[{'visible': [False, False, True]},\n",
    "               {'title': 'Total Monthly Mentions of Flu-related Words'}])\n",
    "]\n",
    "\n",
    "# --- Layout with horizontal seed word legend below the chart ---\n",
    "fig.update_layout(\n",
    "    updatemenus=[dict(\n",
    "        type='buttons',\n",
    "        direction='left',\n",
    "        buttons=buttons,\n",
    "        x=0.5, xanchor='center',\n",
    "        y=1.15, yanchor='top'\n",
    "    )],\n",
    "    title='Total Mentions of Flu-related Words Over Time',\n",
    "    xaxis_title='Date',\n",
    "    yaxis_title='Absolute Frequency (Total)',\n",
    "    template='plotly_white',\n",
    "    hovermode='x unified',\n",
    "    width=950,\n",
    "    height=550,\n",
    "    margin=dict(b=120)  # make room for the seed word legend\n",
    ")\n",
    "\n",
    "# --- Add horizontal seed word display below the X-axis ---\n",
    "seed_words = ['grippe','tote','influenza','pandemie','epidemie',\n",
    "              'krankheit','hoch','kampf','kreis','mensch','täglich','tot']\n",
    "\n",
    "fig.add_annotation(\n",
    "    text=\"<b>Seed Words:</b> \" + \" • \".join(seed_words),\n",
    "    showarrow=False,\n",
    "    xref='paper', yref='paper',\n",
    "    x=0.5, y=-0.25,  # below the X-axis\n",
    "    xanchor='center',\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd1382a-dfcc-427b-b4bf-4436c9446152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_22.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.area(monthly_total, x='month', y='total_abs_freq', title=\"Wave-like Public Attention\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26ed3c74-7d9b-4f57-846f-f3c255493110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_27.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "daily_total['month'] = daily_total['date'].dt.month\n",
    "daily_total['year'] = daily_total['date'].dt.year\n",
    "daily_total['day'] = daily_total['date'].dt.day\n",
    "\n",
    "px.density_heatmap(\n",
    "    daily_total, x='day', y='month', z='total_abs_freq', facet_col='year',\n",
    "    color_continuous_scale='Reds', title=\"Daily Mentions Heatmap\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1be2fbbe-2340-4035-90e5-9507274592dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"100%\"\n",
       "    height=\"545px\"\n",
       "    src=\"iframe_figures/figure_20.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(\n",
    "    lemma_date_counts[lemma_date_counts['Lemma_lower'].isin(seed_words)],\n",
    "    x='Lemma_lower', y='count', color='Lemma_lower',\n",
    "    animation_frame='date', range_y=[0, lemma_date_counts['count'].max()],\n",
    "    title=\"Daily Mentions of Each Seed Word Over Time\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf72084-4d3b-4ee3-ad39-7dc754ecc12b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
